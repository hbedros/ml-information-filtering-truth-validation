{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Bigram Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['title', 'text', 'subject', 'date'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(true_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy: 0.4603\n",
      "\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "Government News       0.08      0.10      0.09       316\n",
      "    Middle-east       0.12      0.14      0.13       159\n",
      "           News       0.84      0.91      0.87      1821\n",
      "        US_News       0.08      0.08      0.08       160\n",
      "      left-news       0.13      0.12      0.12       897\n",
      "       politics       0.28      0.24      0.26      1344\n",
      "\n",
      "       accuracy                           0.46      4697\n",
      "      macro avg       0.26      0.27      0.26      4697\n",
      "   weighted avg       0.44      0.46      0.45      4697\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import the Naive Bayes model and dataset\n",
    "from models.naive_bayes_bigram_model import NaiveBayesBigram\n",
    "from utils.utils import fake_df\n",
    "\n",
    "# Initialize the Naive Bayes model\n",
    "nb_model = NaiveBayesBigram()\n",
    "\n",
    "# Train the model on the dataset\n",
    "# Assuming `text` is the column with text data and `label` is the column with labels\n",
    "results = nb_model.train(fake_df, text_column='text', label_column='subject')\n",
    "\n",
    "# Print the results\n",
    "print(f\"Naive Bayes Accuracy: {results['accuracy']:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(results['classification_report'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis of Results\n",
    "Class Imbalance:\n",
    "\n",
    "The Classification Report shows that the News class has significantly higher support (1821 samples) compared to other classes like Middle-east (159 samples) or US_News (160 samples).\n",
    "This imbalance likely skews the model's predictions toward the majority class (News), as evidenced by its high precision, recall, and F1-score.\n",
    "Poor Performance on Minority Classes:\n",
    "\n",
    "Classes like Government News, Middle-east, and US_News have very low precision, recall, and F1-scores, indicating that the model struggles to correctly classify these categories.\n",
    "Weighted Average:\n",
    "\n",
    "The weighted average F1-score is 0.45, which reflects the model's overall performance across all classes, weighted by the number of samples in each class.\n",
    "Naive Bayes Limitations:\n",
    "\n",
    "Naive Bayes assumes that features (bigrams in this case) are conditionally independent, which may not hold true for text data.\n",
    "The model may not capture the contextual relationships between words as effectively as more advanced models like BERT.\n",
    "\n",
    "Future: we will use techniques like SMOTE (Synthetic Minority Oversampling Technique) or random oversampling to balance the dataset.\n",
    "\n",
    "\n",
    "**Then will compare with Advanced Models**\n",
    "\n",
    "LDA + BERT Hybrid:\n",
    "Compare the Naive Bayes results with your LDA + BERT pipeline to validate your hypothesis that the hybrid approach will outperform simpler models like Naive Bayes.\n",
    "\n",
    "**Lastly will use Dimensionality Reduction for Visualization**\n",
    "\n",
    "Visualize the bigram features using dimensionality reduction techniques like PCA or t-SNE to understand how well the classes are separated in the feature space.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (notebook)",
   "language": "python",
   "name": "notebook"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
