{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efbcb374",
   "metadata": {},
   "source": [
    "# LDA + BERT Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99a0179",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Check if the modules can be imported\n",
    "try:\n",
    "    import pipeline.pipeline\n",
    "    print(\"Pipeline module imported successfully!\")\n",
    "except ImportError as e:\n",
    "    print(\"Error importing pipeline:\", e)\n",
    "\n",
    "try:\n",
    "    import utils.utils\n",
    "    print(\"Utils module imported successfully!\")\n",
    "except ImportError as e:\n",
    "    print(\"Error importing utils:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1381b9cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'pipeline.pipeline' from '/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py'>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "from pipeline import pipeline  # Adjust the import based on your file structure\n",
    "\n",
    "# Reload the pipeline module\n",
    "importlib.reload(pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94954be",
   "metadata": {},
   "source": [
    "# use this to generate processed LDA + BERT CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2725a7e5-1b7d-4228-85ab-67c19dbeb1f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Queries from Topics: ['σι keting ky kxdx kx', 'σι keting ky kxdx kx', 'σι keting ky kxdx kx', 'model regression data figure residuals', 'σι keting ky kxdx kx']\n",
      "Query Embedding Shape: torch.Size([384])\n",
      "Text Embeddings Shape: torch.Size([1, 384])\n",
      "Similarities Shape: torch.Size([1])\n",
      "Query Embedding Shape: torch.Size([384])\n",
      "Text Embeddings Shape: torch.Size([1, 384])\n",
      "Similarities Shape: torch.Size([1])\n",
      "Query Embedding Shape: torch.Size([384])\n",
      "Text Embeddings Shape: torch.Size([1, 384])\n",
      "Similarities Shape: torch.Size([1])\n",
      "Query Embedding Shape: torch.Size([384])\n",
      "Text Embeddings Shape: torch.Size([1, 384])\n",
      "Similarities Shape: torch.Size([1])\n",
      "Query Embedding Shape: torch.Size([384])\n",
      "Text Embeddings Shape: torch.Size([1, 384])\n",
      "Similarities Shape: torch.Size([1])\n",
      "                        _id                                    filename  \\\n",
      "0  67ef012fb79a5a82f4edd5b4  A Modern Approach to Regression with R.pdf   \n",
      "\n",
      "                                                text      contentType  topic  \\\n",
      "0  springer texts statistics series editors g cas...  application/pdf      3   \n",
      "\n",
      "   relevant_to_σι keting ky kxdx kx  similarity_to_σι keting ky kxdx kx  \\\n",
      "0                             False                            0.100853   \n",
      "\n",
      "   relevant_to_model regression data figure residuals  \\\n",
      "0                                              False    \n",
      "\n",
      "   similarity_to_model regression data figure residuals  embedding_0  ...  \\\n",
      "0                                           0.139493       -0.031734  ...   \n",
      "\n",
      "   embedding_374  embedding_375  embedding_376  embedding_377  embedding_378  \\\n",
      "0      -0.028678       0.112397         0.0506       0.079453       0.046195   \n",
      "\n",
      "   embedding_379  embedding_380  embedding_381  embedding_382  embedding_383  \n",
      "0      -0.004007       0.049329      -0.047665       0.035842      -0.015718  \n",
      "\n",
      "[1 rows x 393 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n",
      "/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/pipeline/pipeline.py:119: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "# Import the pipeline function and the datasets\n",
    "from pipeline.pipeline import pipeline\n",
    "from utils.utils import true_df, fake_df, marr_df\n",
    "\n",
    "# Define a query for contextual filtering\n",
    "# query = None\n",
    "\n",
    "# Preprocess the marr_df to handle missing text values\n",
    "marr_df = marr_df.dropna(subset=['text'])\n",
    "\n",
    "# Use a smaller dataset for testing (optional)\n",
    "# marr_df = marr_df.sample(1000, random_state=42)  # Reduce dataset size for faster testing\n",
    "\n",
    "# Run the pipeline\n",
    "# processed_df, lda_model, vectorizer = pipeline(true_df, text_column='subject', n_topics=2)\n",
    "# processed_df, lda_model, vectorizer = pipeline(fake_df, text_column='text', n_topics=5, threshold=0.2)\n",
    "processed_df, lda_model, vectorizer = pipeline(marr_df, text_column='text', n_topics=5, threshold=0.2)\n",
    "\n",
    "# Preview the results\n",
    "print(processed_df.head())\n",
    "\n",
    "# Save the processed DataFrame to a CSV file (optional)\n",
    "processed_df.to_csv(\"lda_bert_processed_marr.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1635f726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Sample Extracted Text ===\n",
      "['CHAPMAN & HALL/CRC  \\nTexts in Statistic al Science Series  \\nSeries Editors \\nBradley P.Carlin, University of Minnesota, USA  \\nChris Chatfield, University of Bath, UK  \\nMartin Tanner, Northwestern University, USA  \\nJim Zidek, University of British Columbia, Canada  \\nAnalysis of Failure and Survival Data  \\nPeter J.Smith \\nThe Analysis and Interpretation of Multivariate Data for Social Scientists  \\nDavid J.Bartholomew, Fiona Steele, Irini Moustaki, and Jane Galbraith \\nThe Analysis of Time Series—A n Introduction, Sixth Edition  \\nChris Chatfield \\nApplied Bayesian Forecasting and Time Series Analysis  \\nA.Pole, M.West and J.Harrison \\nApplied Nonparametric Statisti cal Methods, Third Edition  \\nP.Sprent and N.C.Smeeton \\nApplied Statistics—Handbook of GENSTAT Analysis  \\nE.J.Snell and H.Simpson \\nApplied Statistics—Principles and Examples  \\nD.R.Cox and E.J.Snell \\nBayes and Empirical Bayes Methods for Data Analysis, Second Edition  \\nBradley P.Carlin and Thomas A.Louis \\nBayesian Data Analysis, Second Edition  \\nAndrew Gelman, John B.Carlin, Hal S.Stern, and Donald B.Rubin \\nBeyond ANOVA—Basics of Applied Statistics  \\nR.G.Miller, Jr. \\n ', 'Computer-Aided Multivariate Analysis, Fourth Edition  \\nA.A.Afifi and V.A.Clark \\nA Course in Categorical Data Analysis  \\nT.Leonard \\nA Course in Large Sample Theory  \\nT.S.Ferguson \\nData Driven Statistical Methods  \\nP.Sprent \\nDecision Analysis—A Bayesian Approach  \\nJ.Q.Smith \\nElementary Applications of Prob ability Theory, Second Edition  \\nH.C.Tuckwell \\nElements of Simulation  \\nB.J.T.Morgan \\nEpidemiology—Study Design and Data Analysis, Second Edition  \\nM.Woodward \\nEssential Statistics, Fourth Edition  \\nD.A.G.Rees \\nExtending the Linear Model with R: Generalized Linear, Mixed Effects and \\nNonparametric Regression Models  \\nJulian J.Faraway \\nA First Course in Linear Model Theory  \\nNalini Ravishanker and Dipak K.Dey \\nInterpreting Data—A First Course in Statistics  \\nA.J.B.Anderson \\nAn Introduction to Generalized Linear Models, Second Edition  \\nA.J.Dobson \\nIntroduction to Multivariate Analysis  \\nC.Chatfield and A.J.Collins \\nIntroduction to Optimization Methods and Their Applications in Statistics  \\nB.S.Everitt ', 'Large Sample Methods in Statistics  \\nP.K.Sen and J.da Motta Singer \\nLinear Models with R  \\nJulian J.Faraway \\nMarkov Chain Monte Carl o—Stochastic Simulation  for Bayesian Inference  \\nD.Gamerman \\nMathematical Statistics  \\nK.Knight \\nModeling and Analysis of Stochastic Systems  \\nV.Kulkarni \\nModelling Binary Data, Second Edition  \\nD.Collett \\nModelling Survival Data in Medical Research, Second Edition  \\nD.Collett \\nMultivariate Analysis of Variance and Repeated Measures—A Practical Approach \\nfor Behavioural Scientists  \\nD.J.Hand and C.C.Taylor \\nMultivariate Statistics—A Practical Approach  \\nB.Flury and H.Riedwyl \\nPractical Data Analysis for Designed Experiments  \\nB.S.Yandell \\nPractical Longitudinal Data Analysis  \\nD.J.Hand and M.Crowder \\nPractical Statistics for Medical Research  \\nD.G.Altman \\nProbability—Methods and Measurement  \\nA.O’Hagan \\nProblem Solving—A Statistician’s Guide, Second Edition  \\nC.Chatfield \\nRandomization, Bootstrap and Monte Carlo Methods in Biology, Second Edition  \\nB.F.J.Manly ', 'Readings in Decision Analysis  \\nS.French \\nSampling Methodologies with Applications  \\nPoduri S.R.S.Rao \\nSpatial Data Analysis  \\nOliver Schabenberger and Carol A.Gotway \\nStatistical Analysis of Reliability Data  \\nM.J.Crowder, A.C.Kimber, T.J.Sweeting, and R.L.Smith \\nStatistical Methods for Spatial Data Analysis  \\nOliver Schabenberger and Carol A.Gotway \\nStatistical Methods for SPC and TQM  \\nD.Bissell \\nStatistical Methods in Agriculture and Experimental Biology,  Second Edition  \\nR.Mead, R.N.Curnow , and A.M.Hasted \\nStatistical Process Control—Theo ry and Practice, Third Edition  \\nG.B.Wetherill and D.W.Brown \\nStatistical Theory, Fourth Edition  \\nB.W.Lindgren \\nStatistics for Accountants  \\nS.Letchford \\nStatistics for Epidemiology  \\nNicholas P.Jewell \\nStatistics for Technology—A Course in Applied Statistics, Third Edition  \\nC.Chatfield \\nStatistics in Engineering—A Practical Approach  \\nA.V.Metcalfe \\nStatistics in Research and Development, Second Edition  \\nR.Caulcutt \\nSurvival Analysis Using S—Analysis of Time-to-Event Data  \\nMara Tableman and Jong Sung Kim \\n ', 'The Theory of Linear Models  \\nB.Jørgensen \\nTexts in Statistical Science ']\n",
      "Generated Queries from Topics: ['model fit linear likelihood value', 'model plot data response residuals', 'data effects model random analysis', 'data model tree linear regression', 'model data test deviance log']\n",
      "Generated Queries: ['relevant_to_model fit linear likelihood value', 'relevant_to_model plot data response residuals', 'relevant_to_data effects model random analysis', 'relevant_to_data model tree linear regression', 'relevant_to_model data test deviance log']\n",
      "Relevance Counts:\n",
      "relevant_to_model fit linear likelihood value: relevant_to_model fit linear likelihood value\n",
      "False    132\n",
      "True      34\n",
      "Name: count, dtype: int64\n",
      "relevant_to_model plot data response residuals: relevant_to_model plot data response residuals\n",
      "False    102\n",
      "True      64\n",
      "Name: count, dtype: int64\n",
      "relevant_to_data effects model random analysis: relevant_to_data effects model random analysis\n",
      "False    106\n",
      "True      60\n",
      "Name: count, dtype: int64\n",
      "relevant_to_data model tree linear regression: relevant_to_data model tree linear regression\n",
      "False    135\n",
      "True      31\n",
      "Name: count, dtype: int64\n",
      "relevant_to_model data test deviance log: relevant_to_model data test deviance log\n",
      "False    121\n",
      "True      45\n",
      "Name: count, dtype: int64\n",
      "Processed DataFrame Shape: (166, 12)\n",
      "=== Processed PDF Data ===\n",
      "                                                text  topic  \\\n",
      "1  Computer-Aided Multivariate Analysis, Fourth E...      3   \n",
      "2  Large Sample Methods in Statistics  \\nP.K.Sen ...      3   \n",
      "4  The Theory of Linear Models  \\nB.Jørgensen \\nT...      4   \n",
      "5  Extending the Linear Model with \\nR \\nGenerali...      2   \n",
      "8  Preface  \\nLinear models are central to th e p...      3   \n",
      "\n",
      "   relevant_to_model fit linear likelihood value  \\\n",
      "1                                          False   \n",
      "2                                          False   \n",
      "4                                          False   \n",
      "5                                          False   \n",
      "8                                          False   \n",
      "\n",
      "   similarity_to_model fit linear likelihood value  \\\n",
      "1                                         0.204230   \n",
      "2                                         0.146612   \n",
      "4                                         0.252437   \n",
      "5                                         0.260462   \n",
      "8                                         0.254341   \n",
      "\n",
      "   relevant_to_model plot data response residuals  \\\n",
      "1                                           False   \n",
      "2                                           False   \n",
      "4                                           False   \n",
      "5                                            True   \n",
      "8                                            True   \n",
      "\n",
      "   similarity_to_model plot data response residuals  \\\n",
      "1                                          0.180367   \n",
      "2                                          0.111452   \n",
      "4                                          0.182922   \n",
      "5                                          0.348526   \n",
      "8                                          0.338382   \n",
      "\n",
      "   relevant_to_data effects model random analysis  \\\n",
      "1                                            True   \n",
      "2                                            True   \n",
      "4                                            True   \n",
      "5                                            True   \n",
      "8                                            True   \n",
      "\n",
      "   similarity_to_data effects model random analysis  \\\n",
      "1                                          0.426097   \n",
      "2                                          0.390927   \n",
      "4                                          0.344945   \n",
      "5                                          0.463627   \n",
      "8                                          0.553141   \n",
      "\n",
      "   relevant_to_data model tree linear regression  \\\n",
      "1                                          False   \n",
      "2                                          False   \n",
      "4                                           True   \n",
      "5                                           True   \n",
      "8                                           True   \n",
      "\n",
      "   similarity_to_data model tree linear regression  \\\n",
      "1                                         0.289887   \n",
      "2                                         0.162072   \n",
      "4                                         0.311130   \n",
      "5                                         0.346932   \n",
      "8                                         0.401222   \n",
      "\n",
      "   relevant_to_model data test deviance log  \\\n",
      "1                                     False   \n",
      "2                                     False   \n",
      "4                                     False   \n",
      "5                                     False   \n",
      "8                                     False   \n",
      "\n",
      "   similarity_to_model data test deviance log  \n",
      "1                                    0.211215  \n",
      "2                                    0.146106  \n",
      "4                                    0.131950  \n",
      "5                                    0.163426  \n",
      "8                                    0.228396  \n",
      "Processed PDF data saved to 'processed_pdf.csv'\n",
      "   relevant_to_model fit linear likelihood value  \\\n",
      "1                                          False   \n",
      "2                                          False   \n",
      "4                                          False   \n",
      "5                                          False   \n",
      "8                                          False   \n",
      "\n",
      "   relevant_to_model plot data response residuals  \\\n",
      "1                                           False   \n",
      "2                                           False   \n",
      "4                                           False   \n",
      "5                                            True   \n",
      "8                                            True   \n",
      "\n",
      "   relevant_to_data effects model random analysis  \\\n",
      "1                                            True   \n",
      "2                                            True   \n",
      "4                                            True   \n",
      "5                                            True   \n",
      "8                                            True   \n",
      "\n",
      "   relevant_to_data model tree linear regression  \\\n",
      "1                                          False   \n",
      "2                                          False   \n",
      "4                                           True   \n",
      "5                                           True   \n",
      "8                                           True   \n",
      "\n",
      "   relevant_to_model data test deviance log  \n",
      "1                                     False  \n",
      "2                                     False  \n",
      "4                                     False  \n",
      "5                                     False  \n",
      "8                                     False  \n",
      "Generated Queries: ['relevant_to_model fit linear likelihood value', 'relevant_to_model plot data response residuals', 'relevant_to_data effects model random analysis', 'relevant_to_data model tree linear regression', 'relevant_to_model data test deviance log']\n"
     ]
    }
   ],
   "source": [
    "# process PDF\n",
    "from importlib import reload\n",
    "from pipeline import pipeline\n",
    "\n",
    "reload(pipeline)\n",
    "\n",
    "from PyPDF2 import PdfReader\n",
    "import pandas as pd\n",
    "from pipeline.pipeline import process_pdf_with_pipeline\n",
    "\n",
    "# Example: Path to the PDF file\n",
    "pdf_file_path = \"/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/src/Extending the Linear Model with R.pdf\"\n",
    "\n",
    "# Process the PDF file using the new pipeline function\n",
    "processed_pdf_df = process_pdf_with_pipeline(\n",
    "    pdf_file_path=pdf_file_path,\n",
    "    n_topics=5,  # Number of topics for LDA\n",
    "    threshold=0.3,  # Similarity threshold for BERT filtering\n",
    "    bert_model=\"all-MiniLM-L6-v2\",  # Pre-trained Sentence-Transformers model\n",
    "    top_n_words=5  # Number of top words for query generation\n",
    ")\n",
    "\n",
    "# Preview the processed results\n",
    "print(\"=== Processed PDF Data ===\")\n",
    "print(processed_pdf_df.head())\n",
    "\n",
    "# Save the processed DataFrame to a CSV file (optional)\n",
    "processed_pdf_df.to_csv(\"lda_bert_processed.csv\", index=False)\n",
    "print(\"Processed PDF data saved to 'lda_bert_processed.csv'\")\n",
    "print(processed_pdf_df[[col for col in processed_pdf_df.columns if \"relevant_to\" in col]].head())\n",
    "queries = [col for col in processed_pdf_df.columns if \"relevant_to\" in col]\n",
    "print(f\"Generated Queries: {queries}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68303c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Columns: 410 entries, title to embedding_383\n",
      "dtypes: bool(10), float64(394), int64(2), object(4)\n",
      "memory usage: 3.1+ MB\n",
      "None\n",
      "                                               title  \\\n",
      "0  ABOUT HILLARY’S COUGH: We Discovered The Secre...   \n",
      "1  BREAKING: OBAMACARE REPEAL Clears First Hurdle...   \n",
      "2  ‘SLEEPY’ JUSTICE GINSBURG: Excites Crowd By Sa...   \n",
      "3   WATCH: Kellyanne Conway Very Upset Hillary Cl...   \n",
      "4   GOP Gives Trump The Middle Finger, Prepares T...   \n",
      "\n",
      "                                                text    subject  \\\n",
      "0                                                NaN   politics   \n",
      "1  senate voted afternoon proceed resolution con ...   politics   \n",
      "2  much scotus political check comments equality ...  left-news   \n",
      "3  white house counselor kellyanne conway crawled...       News   \n",
      "4  donald trump may decided russia going america ...       News   \n",
      "\n",
      "               date  label  topic  \\\n",
      "0      Jul 20, 2016      1      0   \n",
      "1       Jan 4, 2017      1      1   \n",
      "2       Feb 7, 2017      1      2   \n",
      "3   August 24, 2017      1      2   \n",
      "4  December 9, 2016      1      3   \n",
      "\n",
      "   relevant_to_said police people obama government  \\\n",
      "0                                            False   \n",
      "1                                             True   \n",
      "2                                            False   \n",
      "3                                             True   \n",
      "4                                             True   \n",
      "\n",
      "   similarity_to_said police people obama government  \\\n",
      "0                                           0.149932   \n",
      "1                                           0.285427   \n",
      "2                                           0.136729   \n",
      "3                                           0.312453   \n",
      "4                                           0.233059   \n",
      "\n",
      "   relevant_to_clinton news fbi said trump  \\\n",
      "0                                    False   \n",
      "1                                     True   \n",
      "2                                    False   \n",
      "3                                     True   \n",
      "4                                     True   \n",
      "\n",
      "   similarity_to_clinton news fbi said trump  ...  embedding_374  \\\n",
      "0                                   0.136666  ...       0.107304   \n",
      "1                                   0.267494  ...       0.032324   \n",
      "2                                   0.164834  ...       0.000653   \n",
      "3                                   0.421582  ...       0.001442   \n",
      "4                                   0.376952  ...       0.023286   \n",
      "\n",
      "   embedding_375  embedding_376  embedding_377  embedding_378  embedding_379  \\\n",
      "0       0.011428       0.013367      -0.012748       0.061454       0.035641   \n",
      "1       0.075093       0.015337      -0.040242       0.055491      -0.041336   \n",
      "2      -0.013880       0.012120       0.046314      -0.071702       0.027118   \n",
      "3       0.007310      -0.033810      -0.002779      -0.048864       0.027098   \n",
      "4       0.100243       0.062660       0.041937      -0.036668      -0.024500   \n",
      "\n",
      "   embedding_380  embedding_381  embedding_382  embedding_383  \n",
      "0       0.158746       0.126410       0.046549      -0.015717  \n",
      "1       0.059529       0.060070       0.010363       0.006843  \n",
      "2       0.088051      -0.073087       0.042523      -0.028412  \n",
      "3       0.066670      -0.046421       0.024674       0.018947  \n",
      "4      -0.032779      -0.117011      -0.023262       0.000183  \n",
      "\n",
      "[5 rows x 410 columns]\n",
      "Embedding Columns: ['embedding_0', 'embedding_1', 'embedding_2', 'embedding_3', 'embedding_4', 'embedding_5', 'embedding_6', 'embedding_7', 'embedding_8', 'embedding_9', 'embedding_10', 'embedding_11', 'embedding_12', 'embedding_13', 'embedding_14', 'embedding_15', 'embedding_16', 'embedding_17', 'embedding_18', 'embedding_19', 'embedding_20', 'embedding_21', 'embedding_22', 'embedding_23', 'embedding_24', 'embedding_25', 'embedding_26', 'embedding_27', 'embedding_28', 'embedding_29', 'embedding_30', 'embedding_31', 'embedding_32', 'embedding_33', 'embedding_34', 'embedding_35', 'embedding_36', 'embedding_37', 'embedding_38', 'embedding_39', 'embedding_40', 'embedding_41', 'embedding_42', 'embedding_43', 'embedding_44', 'embedding_45', 'embedding_46', 'embedding_47', 'embedding_48', 'embedding_49', 'embedding_50', 'embedding_51', 'embedding_52', 'embedding_53', 'embedding_54', 'embedding_55', 'embedding_56', 'embedding_57', 'embedding_58', 'embedding_59', 'embedding_60', 'embedding_61', 'embedding_62', 'embedding_63', 'embedding_64', 'embedding_65', 'embedding_66', 'embedding_67', 'embedding_68', 'embedding_69', 'embedding_70', 'embedding_71', 'embedding_72', 'embedding_73', 'embedding_74', 'embedding_75', 'embedding_76', 'embedding_77', 'embedding_78', 'embedding_79', 'embedding_80', 'embedding_81', 'embedding_82', 'embedding_83', 'embedding_84', 'embedding_85', 'embedding_86', 'embedding_87', 'embedding_88', 'embedding_89', 'embedding_90', 'embedding_91', 'embedding_92', 'embedding_93', 'embedding_94', 'embedding_95', 'embedding_96', 'embedding_97', 'embedding_98', 'embedding_99', 'embedding_100', 'embedding_101', 'embedding_102', 'embedding_103', 'embedding_104', 'embedding_105', 'embedding_106', 'embedding_107', 'embedding_108', 'embedding_109', 'embedding_110', 'embedding_111', 'embedding_112', 'embedding_113', 'embedding_114', 'embedding_115', 'embedding_116', 'embedding_117', 'embedding_118', 'embedding_119', 'embedding_120', 'embedding_121', 'embedding_122', 'embedding_123', 'embedding_124', 'embedding_125', 'embedding_126', 'embedding_127', 'embedding_128', 'embedding_129', 'embedding_130', 'embedding_131', 'embedding_132', 'embedding_133', 'embedding_134', 'embedding_135', 'embedding_136', 'embedding_137', 'embedding_138', 'embedding_139', 'embedding_140', 'embedding_141', 'embedding_142', 'embedding_143', 'embedding_144', 'embedding_145', 'embedding_146', 'embedding_147', 'embedding_148', 'embedding_149', 'embedding_150', 'embedding_151', 'embedding_152', 'embedding_153', 'embedding_154', 'embedding_155', 'embedding_156', 'embedding_157', 'embedding_158', 'embedding_159', 'embedding_160', 'embedding_161', 'embedding_162', 'embedding_163', 'embedding_164', 'embedding_165', 'embedding_166', 'embedding_167', 'embedding_168', 'embedding_169', 'embedding_170', 'embedding_171', 'embedding_172', 'embedding_173', 'embedding_174', 'embedding_175', 'embedding_176', 'embedding_177', 'embedding_178', 'embedding_179', 'embedding_180', 'embedding_181', 'embedding_182', 'embedding_183', 'embedding_184', 'embedding_185', 'embedding_186', 'embedding_187', 'embedding_188', 'embedding_189', 'embedding_190', 'embedding_191', 'embedding_192', 'embedding_193', 'embedding_194', 'embedding_195', 'embedding_196', 'embedding_197', 'embedding_198', 'embedding_199', 'embedding_200', 'embedding_201', 'embedding_202', 'embedding_203', 'embedding_204', 'embedding_205', 'embedding_206', 'embedding_207', 'embedding_208', 'embedding_209', 'embedding_210', 'embedding_211', 'embedding_212', 'embedding_213', 'embedding_214', 'embedding_215', 'embedding_216', 'embedding_217', 'embedding_218', 'embedding_219', 'embedding_220', 'embedding_221', 'embedding_222', 'embedding_223', 'embedding_224', 'embedding_225', 'embedding_226', 'embedding_227', 'embedding_228', 'embedding_229', 'embedding_230', 'embedding_231', 'embedding_232', 'embedding_233', 'embedding_234', 'embedding_235', 'embedding_236', 'embedding_237', 'embedding_238', 'embedding_239', 'embedding_240', 'embedding_241', 'embedding_242', 'embedding_243', 'embedding_244', 'embedding_245', 'embedding_246', 'embedding_247', 'embedding_248', 'embedding_249', 'embedding_250', 'embedding_251', 'embedding_252', 'embedding_253', 'embedding_254', 'embedding_255', 'embedding_256', 'embedding_257', 'embedding_258', 'embedding_259', 'embedding_260', 'embedding_261', 'embedding_262', 'embedding_263', 'embedding_264', 'embedding_265', 'embedding_266', 'embedding_267', 'embedding_268', 'embedding_269', 'embedding_270', 'embedding_271', 'embedding_272', 'embedding_273', 'embedding_274', 'embedding_275', 'embedding_276', 'embedding_277', 'embedding_278', 'embedding_279', 'embedding_280', 'embedding_281', 'embedding_282', 'embedding_283', 'embedding_284', 'embedding_285', 'embedding_286', 'embedding_287', 'embedding_288', 'embedding_289', 'embedding_290', 'embedding_291', 'embedding_292', 'embedding_293', 'embedding_294', 'embedding_295', 'embedding_296', 'embedding_297', 'embedding_298', 'embedding_299', 'embedding_300', 'embedding_301', 'embedding_302', 'embedding_303', 'embedding_304', 'embedding_305', 'embedding_306', 'embedding_307', 'embedding_308', 'embedding_309', 'embedding_310', 'embedding_311', 'embedding_312', 'embedding_313', 'embedding_314', 'embedding_315', 'embedding_316', 'embedding_317', 'embedding_318', 'embedding_319', 'embedding_320', 'embedding_321', 'embedding_322', 'embedding_323', 'embedding_324', 'embedding_325', 'embedding_326', 'embedding_327', 'embedding_328', 'embedding_329', 'embedding_330', 'embedding_331', 'embedding_332', 'embedding_333', 'embedding_334', 'embedding_335', 'embedding_336', 'embedding_337', 'embedding_338', 'embedding_339', 'embedding_340', 'embedding_341', 'embedding_342', 'embedding_343', 'embedding_344', 'embedding_345', 'embedding_346', 'embedding_347', 'embedding_348', 'embedding_349', 'embedding_350', 'embedding_351', 'embedding_352', 'embedding_353', 'embedding_354', 'embedding_355', 'embedding_356', 'embedding_357', 'embedding_358', 'embedding_359', 'embedding_360', 'embedding_361', 'embedding_362', 'embedding_363', 'embedding_364', 'embedding_365', 'embedding_366', 'embedding_367', 'embedding_368', 'embedding_369', 'embedding_370', 'embedding_371', 'embedding_372', 'embedding_373', 'embedding_374', 'embedding_375', 'embedding_376', 'embedding_377', 'embedding_378', 'embedding_379', 'embedding_380', 'embedding_381', 'embedding_382', 'embedding_383']\n",
      "Shape of X: (1000, 384)\n",
      "Shape of y: (1000,)\n"
     ]
    }
   ],
   "source": [
    "# checks if the processed DataFrame has embeddings and labels\n",
    "import pandas as pd\n",
    "\n",
    "# Load the processed DataFrame\n",
    "processed_csv_path = \"/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/notebooks/lda_bert_processed_fake.csv\"\n",
    "processed_df = pd.read_csv(processed_csv_path)\n",
    "\n",
    "# Check the processed DataFrame\n",
    "print(\"Processed DataFrame Info:\")\n",
    "print(processed_df.info())\n",
    "print(processed_df.head())\n",
    "\n",
    "# Ensure the processed DataFrame has embeddings and labels\n",
    "embedding_columns = [col for col in processed_df.columns if col.startswith('embedding')]\n",
    "print(\"Embedding Columns:\", embedding_columns)\n",
    "\n",
    "if not embedding_columns:\n",
    "    raise ValueError(\"No embedding columns found in the processed DataFrame.\")\n",
    "\n",
    "# Extract features (X) and labels (y)\n",
    "X = processed_df[embedding_columns]\n",
    "y = processed_df['label']\n",
    "\n",
    "# Check the shapes of X and y\n",
    "print(\"Shape of X:\", X.shape)\n",
    "print(\"Shape of y:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf1e38a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Embedding Shape: torch.Size([384])\n",
      "Text Embeddings Shape: torch.Size([4, 384])\n",
      "Similarities Shape: torch.Size([4])\n",
      "Relevance: [True, False, False, False]\n",
      "Similarities: [0.65947145 0.02445563 0.37258637 0.15373915]\n",
      "Text Embeddings Shape: (4, 384)\n"
     ]
    }
   ],
   "source": [
    "from pipeline.pipeline import bert_contextual_filtering\n",
    "\n",
    "# Test prompt\n",
    "texts = [\n",
    "    \"The government announced new policies today.\",\n",
    "    \"Sports events are being postponed due to weather conditions.\",\n",
    "    \"The president gave a speech about economic reforms.\",\n",
    "    \"Students are protesting against tuition hikes.\"\n",
    "]\n",
    "query = \"government policies\"\n",
    "\n",
    "# Test the function\n",
    "relevance, similarities, text_embeddings = bert_contextual_filtering(\n",
    "    texts, \n",
    "    query, \n",
    "    model_name=\"all-MiniLM-L6-v2\", \n",
    "    threshold=0.5\n",
    ")\n",
    "\n",
    "# Print the outputs\n",
    "print(\"Relevance:\", relevance)\n",
    "print(\"Similarities:\", similarities)\n",
    "print(\"Text Embeddings Shape:\", text_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba39fe61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1 entries, 0 to 0\n",
      "Columns: 393 entries, _id to embedding_383\n",
      "dtypes: bool(2), float64(386), int64(1), object(4)\n",
      "memory usage: 3.2+ KB\n",
      "None\n",
      "                        _id                                    filename  \\\n",
      "0  67ef012fb79a5a82f4edd5b4  A Modern Approach to Regression with R.pdf   \n",
      "\n",
      "                                                text      contentType  topic  \\\n",
      "0  springer texts statistics series editors g cas...  application/pdf      3   \n",
      "\n",
      "   relevant_to_σι keting ky kxdx kx  similarity_to_σι keting ky kxdx kx  \\\n",
      "0                             False                            0.100853   \n",
      "\n",
      "   relevant_to_model regression data figure residuals  \\\n",
      "0                                              False    \n",
      "\n",
      "   similarity_to_model regression data figure residuals  embedding_0  ...  \\\n",
      "0                                           0.139493       -0.031734  ...   \n",
      "\n",
      "   embedding_374  embedding_375  embedding_376  embedding_377  embedding_378  \\\n",
      "0      -0.028678       0.112397         0.0506       0.079453       0.046195   \n",
      "\n",
      "   embedding_379  embedding_380  embedding_381  embedding_382  embedding_383  \n",
      "0      -0.004007       0.049329      -0.047665       0.035842      -0.015718  \n",
      "\n",
      "[1 rows x 393 columns]\n",
      "Embedding Columns: ['embedding_0', 'embedding_1', 'embedding_2', 'embedding_3', 'embedding_4', 'embedding_5', 'embedding_6', 'embedding_7', 'embedding_8', 'embedding_9', 'embedding_10', 'embedding_11', 'embedding_12', 'embedding_13', 'embedding_14', 'embedding_15', 'embedding_16', 'embedding_17', 'embedding_18', 'embedding_19', 'embedding_20', 'embedding_21', 'embedding_22', 'embedding_23', 'embedding_24', 'embedding_25', 'embedding_26', 'embedding_27', 'embedding_28', 'embedding_29', 'embedding_30', 'embedding_31', 'embedding_32', 'embedding_33', 'embedding_34', 'embedding_35', 'embedding_36', 'embedding_37', 'embedding_38', 'embedding_39', 'embedding_40', 'embedding_41', 'embedding_42', 'embedding_43', 'embedding_44', 'embedding_45', 'embedding_46', 'embedding_47', 'embedding_48', 'embedding_49', 'embedding_50', 'embedding_51', 'embedding_52', 'embedding_53', 'embedding_54', 'embedding_55', 'embedding_56', 'embedding_57', 'embedding_58', 'embedding_59', 'embedding_60', 'embedding_61', 'embedding_62', 'embedding_63', 'embedding_64', 'embedding_65', 'embedding_66', 'embedding_67', 'embedding_68', 'embedding_69', 'embedding_70', 'embedding_71', 'embedding_72', 'embedding_73', 'embedding_74', 'embedding_75', 'embedding_76', 'embedding_77', 'embedding_78', 'embedding_79', 'embedding_80', 'embedding_81', 'embedding_82', 'embedding_83', 'embedding_84', 'embedding_85', 'embedding_86', 'embedding_87', 'embedding_88', 'embedding_89', 'embedding_90', 'embedding_91', 'embedding_92', 'embedding_93', 'embedding_94', 'embedding_95', 'embedding_96', 'embedding_97', 'embedding_98', 'embedding_99', 'embedding_100', 'embedding_101', 'embedding_102', 'embedding_103', 'embedding_104', 'embedding_105', 'embedding_106', 'embedding_107', 'embedding_108', 'embedding_109', 'embedding_110', 'embedding_111', 'embedding_112', 'embedding_113', 'embedding_114', 'embedding_115', 'embedding_116', 'embedding_117', 'embedding_118', 'embedding_119', 'embedding_120', 'embedding_121', 'embedding_122', 'embedding_123', 'embedding_124', 'embedding_125', 'embedding_126', 'embedding_127', 'embedding_128', 'embedding_129', 'embedding_130', 'embedding_131', 'embedding_132', 'embedding_133', 'embedding_134', 'embedding_135', 'embedding_136', 'embedding_137', 'embedding_138', 'embedding_139', 'embedding_140', 'embedding_141', 'embedding_142', 'embedding_143', 'embedding_144', 'embedding_145', 'embedding_146', 'embedding_147', 'embedding_148', 'embedding_149', 'embedding_150', 'embedding_151', 'embedding_152', 'embedding_153', 'embedding_154', 'embedding_155', 'embedding_156', 'embedding_157', 'embedding_158', 'embedding_159', 'embedding_160', 'embedding_161', 'embedding_162', 'embedding_163', 'embedding_164', 'embedding_165', 'embedding_166', 'embedding_167', 'embedding_168', 'embedding_169', 'embedding_170', 'embedding_171', 'embedding_172', 'embedding_173', 'embedding_174', 'embedding_175', 'embedding_176', 'embedding_177', 'embedding_178', 'embedding_179', 'embedding_180', 'embedding_181', 'embedding_182', 'embedding_183', 'embedding_184', 'embedding_185', 'embedding_186', 'embedding_187', 'embedding_188', 'embedding_189', 'embedding_190', 'embedding_191', 'embedding_192', 'embedding_193', 'embedding_194', 'embedding_195', 'embedding_196', 'embedding_197', 'embedding_198', 'embedding_199', 'embedding_200', 'embedding_201', 'embedding_202', 'embedding_203', 'embedding_204', 'embedding_205', 'embedding_206', 'embedding_207', 'embedding_208', 'embedding_209', 'embedding_210', 'embedding_211', 'embedding_212', 'embedding_213', 'embedding_214', 'embedding_215', 'embedding_216', 'embedding_217', 'embedding_218', 'embedding_219', 'embedding_220', 'embedding_221', 'embedding_222', 'embedding_223', 'embedding_224', 'embedding_225', 'embedding_226', 'embedding_227', 'embedding_228', 'embedding_229', 'embedding_230', 'embedding_231', 'embedding_232', 'embedding_233', 'embedding_234', 'embedding_235', 'embedding_236', 'embedding_237', 'embedding_238', 'embedding_239', 'embedding_240', 'embedding_241', 'embedding_242', 'embedding_243', 'embedding_244', 'embedding_245', 'embedding_246', 'embedding_247', 'embedding_248', 'embedding_249', 'embedding_250', 'embedding_251', 'embedding_252', 'embedding_253', 'embedding_254', 'embedding_255', 'embedding_256', 'embedding_257', 'embedding_258', 'embedding_259', 'embedding_260', 'embedding_261', 'embedding_262', 'embedding_263', 'embedding_264', 'embedding_265', 'embedding_266', 'embedding_267', 'embedding_268', 'embedding_269', 'embedding_270', 'embedding_271', 'embedding_272', 'embedding_273', 'embedding_274', 'embedding_275', 'embedding_276', 'embedding_277', 'embedding_278', 'embedding_279', 'embedding_280', 'embedding_281', 'embedding_282', 'embedding_283', 'embedding_284', 'embedding_285', 'embedding_286', 'embedding_287', 'embedding_288', 'embedding_289', 'embedding_290', 'embedding_291', 'embedding_292', 'embedding_293', 'embedding_294', 'embedding_295', 'embedding_296', 'embedding_297', 'embedding_298', 'embedding_299', 'embedding_300', 'embedding_301', 'embedding_302', 'embedding_303', 'embedding_304', 'embedding_305', 'embedding_306', 'embedding_307', 'embedding_308', 'embedding_309', 'embedding_310', 'embedding_311', 'embedding_312', 'embedding_313', 'embedding_314', 'embedding_315', 'embedding_316', 'embedding_317', 'embedding_318', 'embedding_319', 'embedding_320', 'embedding_321', 'embedding_322', 'embedding_323', 'embedding_324', 'embedding_325', 'embedding_326', 'embedding_327', 'embedding_328', 'embedding_329', 'embedding_330', 'embedding_331', 'embedding_332', 'embedding_333', 'embedding_334', 'embedding_335', 'embedding_336', 'embedding_337', 'embedding_338', 'embedding_339', 'embedding_340', 'embedding_341', 'embedding_342', 'embedding_343', 'embedding_344', 'embedding_345', 'embedding_346', 'embedding_347', 'embedding_348', 'embedding_349', 'embedding_350', 'embedding_351', 'embedding_352', 'embedding_353', 'embedding_354', 'embedding_355', 'embedding_356', 'embedding_357', 'embedding_358', 'embedding_359', 'embedding_360', 'embedding_361', 'embedding_362', 'embedding_363', 'embedding_364', 'embedding_365', 'embedding_366', 'embedding_367', 'embedding_368', 'embedding_369', 'embedding_370', 'embedding_371', 'embedding_372', 'embedding_373', 'embedding_374', 'embedding_375', 'embedding_376', 'embedding_377', 'embedding_378', 'embedding_379', 'embedding_380', 'embedding_381', 'embedding_382', 'embedding_383']\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'label'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/envs/torchmetal/lib/python3.9/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'label'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Extract features (X) and labels (y)\u001b[39;00m\n\u001b[1;32m     20\u001b[0m X \u001b[38;5;241m=\u001b[39m processed_df[embedding_columns]\n\u001b[0;32m---> 21\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mprocessed_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Check the shapes of X and y\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of X:\u001b[39m\u001b[38;5;124m\"\u001b[39m, X\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torchmetal/lib/python3.9/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/torchmetal/lib/python3.9/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'label'"
     ]
    }
   ],
   "source": [
    "# === Evaluation === Take it from here after Naive Bayes Bigram =====\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Import necessary libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "\n",
    "# === Load Preprocessed Data ===\n",
    "# Provide the path to the preprocessed CSV file\n",
    "processed_csv_path = \"/Users/haigbedros/Desktop/MSDS/Capstone/CODE/ml-models-information-filtering/notebooks/lda_bert_processed_fake.csv\"  # Update this path as needed\n",
    "processed_df = pd.read_csv(processed_csv_path)\n",
    "\n",
    "# Preview the processed DataFrame\n",
    "# print(\"Processed DataFrame Preview:\")\n",
    "# print(processed_df.head())\n",
    "\n",
    "# === Evaluation ===\n",
    "\n",
    "# Ensure the processed DataFrame has embeddings and labels\n",
    "# Assuming the embeddings are stored in columns like 'embedding_1', 'embedding_2', ..., 'embedding_n'\n",
    "embedding_columns = [col for col in processed_df.columns if col.startswith('embedding')]\n",
    "print(\"Embedding Columns:\", embedding_columns)\n",
    "\n",
    "# Extract features (X) and labels (y)\n",
    "X = processed_df[embedding_columns]\n",
    "y = processed_df['label']\n",
    "\n",
    "# Check the shapes of X and y\n",
    "print(\"Shape of X:\", X.shape)\n",
    "print(\"Shape of y:\", y.shape)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a logistic regression model\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7507e6",
   "metadata": {},
   "source": [
    "# this is in case we're combining the DFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d66055",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# combined truth and fake datasets\n",
    "# Add labels to true_df and fake_df\n",
    "true_df['label'] = 0  # True news\n",
    "fake_df['label'] = 1  # Fake news\n",
    "\n",
    "# Drop rows with missing text\n",
    "true_df = true_df.dropna(subset=['text'])\n",
    "fake_df = fake_df.dropna(subset=['text'])\n",
    "\n",
    "# Combine the datasets\n",
    "combined_df = pd.concat([true_df, fake_df], ignore_index=True)\n",
    "\n",
    "# Run the pipeline on the combined dataset\n",
    "processed_df, lda_model, vectorizer = pipeline(combined_df, text_column='text', n_topics=5, threshold=0.2)\n",
    "\n",
    "# Verify the processed DataFrame\n",
    "print(\"Processed DataFrame Info:\")\n",
    "print(processed_df.info())\n",
    "print(processed_df.head())\n",
    "\n",
    "# Extract embeddings and labels\n",
    "embedding_columns = [col for col in processed_df.columns if col.startswith('embedding')]\n",
    "X = processed_df[embedding_columns]\n",
    "y = processed_df['label']\n",
    "\n",
    "# Check the distribution of labels\n",
    "print(\"Label Distribution:\")\n",
    "print(y.value_counts())\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Train and evaluate the model\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (torchmetal)",
   "language": "python",
   "name": "torchmetal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
